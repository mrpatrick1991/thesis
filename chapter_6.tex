\chapter{Conclusions}

\section{The Inverse Problem}

The primary question addressed by this thesis is how much information can reasonably be expected to be obtained from balloon measurements of X-ray spectra. The key results for the analysis methods are as follows:

\begin{itemize}
\item When accompanied by an accurate forward model of the expected instrument response given a precipitating electron spectrum, the electron spectrum can be recovered provided that the measurement noise is low enough. 
\item The required statistical purity in the measured X-ray spectrum depends on the shape of the particular spectrum being recovered, and the amount of detail sought in the solution.
\item Preconditioning techniques such as diagonal scaling improve the condition of the inverse problem with no additional assumptions or bias.
\item Biased estimators, such as truncated singular value decomposition, or Tikhonov regularization, can be applied to the to the inverse problem to make it tractable in realistic simulations and actual experiments. 
\item The application of cross-validation methods provides a way to balance the required stability of the solution against the inherent ill-conditioning of the problem, and is capable of selecting regularization parameters which represent the available information in the data without requiring heuristic arguments or detailed assumptions on the form of the output. 
\end{itemize}

These conclusions, when taken together, form a picture of the X-ray inversion problem that is quite different than what is being currently used in experiments. As discussed in Chapter 4, the ill-conditioned inverse problem needs to be addressed to obtain meaningful results. The conventional approach of assuming a particular functional form for the model electron spectrum solves the ill-conditioning by reducing the parameter space of the model. The analysis subsequently uses the well-known $\chi^2$ tests to select an optimal fit and produce an error estimate for that fit. This approach, favoured for its relative simplicity and ability to produce an error estimate, necessarily gives a misleading solution. The reason is that the uncertainty presented by the ill-conditioning of the problem, which results in the vast majority of the uncertainty in the solution, is effectively ``swept under the rug'' and contained in the assumption on the model function chosen for the solution. The remaining error analysis is trivially based on counting statistics and cannot be used to identify between different model spectra, except when significant a-priori information about the precipitating spectrum is known. 

This perspective assumes that very little useful information can be obtained from X-ray measurements. This thesis offers an alternative picture: instead of reducing the information extracted from the data to fit the analysis methods, we adapt the analysis based on what can be determined from the data in a given scenario. This picture is much more optimistic, but critically, it isn't unrealistic. The linearity of the forward problem, combined with the widespread availability of sophisticated particle transport software, makes constructing an accurate representation of the balloon experiments possible. Then, different frameworks for solving the inverse problem can be tried and compared using simulated data. We have found that some relatively simple linear algebra can be used to relieve most of the ill-conditioning of the problem, without loss of generality, but that the transformed problem still requires the use of a biased estimator to give useful, general, results in realistic situations. 

Tikhonov regularization, which is a specific form of the general techniques which modify the singular value spectra of the response matrix of the forward problem, provides a way to continuously adjust the effective dimensionality of the solution, and therefore, the amount of information solved for. Combining this parameterization with cross-validation allows for the optimized selection  of the amount of information contained in the solution, so that it neither underfits, no overfits, the available data. In particular, second-order Tikhonov regularization effectively blurs the detail in the represented solution to match the data, and requires no general assumptions on the shape of the model spectrum. Tikhonov regularization can be done using constraints which further reduce the parameter space of the problem at no additional cost. Particularly, we have found that a simple positivity constraint reduces the dispersion in model spectra. This ensemble of methods is modular - in the sense that additional constraints may be added, without additional loss of generality, if any a-priori information about the precipitating spectrum is known, for example, if magnetically local spacecraft measurements are available.

The primary cost of the use of biased estimators is that they force the mismatch between the information in the input and output of the ill-conditioned problem out in the open - we now have to handle it, and its consequences. This can be taken as a more honest view of the inverse problem in general. While the techniques in Chapter~4 provide strong results when applied to synthetic data, what they cannot do, is provide standard error bars on the shape of the output spectrum. This is because poisson statistics and their simple interpretation no longer apply in the same sense under biased estimators. Statisticians have said that the determination of meaningful error estimates for this kind of problem is one of the frontiers of their research. This places it well outside the scope of this thesis to address, and at the time of writing, only preliminary results exist, and none in the less abstract form needed for practical application to this particular problem. 

The key point is this: it is better to have the fundamental lack of information that causes the ill-conditioning of the inverse problem accounted for in some way, than to conceal it behind an assumption which cannot be justified in most experiments. By honestly attempting to, at least heuristically, account for the amount of information available in a given dataset and in a particular situation, we can learn more than by the misapplication of simple, but tractable, analysis methods.

A secondary conclusion comes from the necessity of a forward model of the precipitation process. The inverse problem, owing to its ill-conditioning, is highly sensitive to both noise, and bias, in the input data. It follows that the accuracy and precision of the forward model used to represent the problem must be high enough not to significantly affect tests on simulated data. The exact instrument response plays a key role in the forward model, and is something that cannot be adequately determined through simulation alone. Lab measurements against known X-ray spectra are required for every different experiment. These are not always easy to accomplish, owing to the somewhat random, and discrete, X-ray peaks produced by commonly available radioactive sources. Further, the instrument response needs to be well-approximated as linear with regards to energy, in order for it to be applied to the linear framework developed to address the inverse problem. The critical simplification made in Chapter~3 was that the instrument response in counts to a monochromatic beam of X-ray photons could be represented using a Green's function approach. Additionally, a large simplification of the forward problem was obtained by essentially ignoring the angular distribution of the precipitating electrons. In this sense it made the problem separable, and reduced the inverse problem to one dimension in energy only.

The environment surrounding the particular detector will need to be simulated in the forward model if it changes significantly between lab testing and installation in a balloon. Balloon experiments are hosted in insulated containers, which are usually surrounded by other flight components, some of which can interact with natural radiation in significant ways. None of this is insurmountable, but needs to be made explicit in light of the primary conclusions. All of the work in Chapter~4 and the subsequent analysis of experimental data applies because the forward model of the experiment was available and verifiable against lab data. Future experiments, even ones flown with changes only to the support systems and flight hardware, rather than instrument itself, will need to re-evaluate the conclusions of Chapter 4, based on the altered forward model of the problem. This could be seen as a lack of generality. It is instead an acknowledgement that the inverse problem is fragile to small changes in the input data and response matrix. This is not as significant of a problem when artificially suppressed by strong assumptions on the output. 

\section{Application to Experimental Data}

When applied to the available body of experimental data (U of C balloon flights and the BARREL campaign), application of the analysis techniques we have developed support the following conclusions:

\begin{itemize}
\item X-ray data obtained from sodium iodide scintillation detectors is sufficient to determine useful information about the precipitating electron spectrum, including the overall electron flux and approximate energy distribution. 
\item In the case of the precipitation event recorded by a balloon when magnetically local spacecraft measurements of the electron spectrum were available, the data can be used to infer a spectrum compatible with the spacecraft measurements, in the sense that the retrieved energy spectrum produces approximately the precipitating electron flux that would be expected based on the spacecraft measurements under the strong scattering assumption with a full loss cone.
\item When the instrument is not performing according to the forward model, as in the U of C balloon flight where it was damaged, our analysis of the data shows a clear problem with the fit. 
\end{itemize}


The first conclusion has been known since the earliest balloon experiments equipped with X-ray detectors were flown. The questions that have persisted over the subsequent decades have all hinged on the interpretation of the measured data, and the amount of information that can be obtained from them. The primary contribution of this thesis to the problem is to demonstrate  that the amount of information available is well-represented as a continuous function of the bias and noise level of the particular experiment flown. This function can be parameterized as a one dimensional optimization, which prevents the introduction of experimenter bias. 

The second conclusion relies on available magnetically connected satellite measurements to the balloon measuring the precipitating spectrum. These occurrences are subset to the available balloon data, and owing to the logistical challenges of timing balloon release against spacecraft orbits, and the expense of balloon flights in general, are not common. The event analysed in Chapter~5 from ~\citet{Halford2015} provides a picture that extends from the trapped population in the radiation belts, through scattering and finally precipitation to the atmosphere and detection by the balloon spectrometer. The measured spectrum at the spacecraft and the spectrum measured by the balloon are not the same - in general, the precipitating population will be subset to the population measured by the spacecraft, and the population will undergo a largely unknown scattering process prior to precipitation. Having measurements of the population from the spacecraft and the balloon does, however, permit a more detailed picture of the end-to-end process to be created. Under the assumption of strong scattering and a full loss cone, and the assumption that the electron population in the lowest pitch angle bin resolved by the spacecraft represents the population in the loss cone, then the precipitating electrons should be subset. Under the additional assumption that the scattering processes responsible for the precipitation are energy selective (which is reasonable, based on the wave-particle dynamics explored in Chapter~2), the balloon spectrum represents the population that was scattered into the loss cone. Since the analysis techniques of Chapter~4 allow the determination of the energy spectrum and total flux of the precipitating population, we have an end-to-end picture of the scattering and precipitation process. Given an estimate of the energy range of the precipitating electrons, the work done by~\citet{kasahara2018} allows the estimation of a precipitating electron flux from the spacecraft data. The results were consistent. Although this is not a direct comparison between two independent sources of data, the overlapping data available between the balloon and the satellite are consistent, which suggests that, given more balloon-satellite conjunctions and measurements, we could show experimentally that the balloon data are sufficient to quantify the precipitating spectrum.

\section{Future Work}

\subsection{Simulations and Models}

To be useful to balloon experiments, the analysis in chapters 3 and 4 needs to be expanded to include different detector designs and specifications. In this thesis, we have demonstrated the effectiveness of one particular detector design, in one experimental setting. Next generation solid state and plastic scintillators have different properties than the sodium iodide crystals used in this work, and their analysis will depend on an accurate representation and simulation. The question of whether a different detector design could be more effective at providing data that solves the inverse problem is so far, unanswered. If differently designed detectors have more complex responses to X-ray photons, which require a different mathematical representation, then much of the work done in Chapter~4 will need to change to account for this. It is not known whether the preconditioning and regularization techniques will still provide useful results given a different detector model.

The analysis techniques developed in Chapter~4 assume an even sampling of energy spectra, using constant-width rectangular bins. This is likely not optimal, and it may be beneficial to increase the effective bin width, and lower the resolution of represented spectra, with increasing energy. There is no reason that this alteration of energy resolution needs to be linear. Accounting for the fact that the lower recorded counts at high energies should have a lower encoded resolution is standard in detector design, and it should be explored for potential benefit in the analysis as well.

The main piece of knowledge that the analysis we have developed does not provide is an estimate on the error in the developed solution. This is a current topic of research in applied statistics, and there are no simple ways to add this function to the analysis method. There are theoretical methods to provide estimates of the spread of confidence intervals over subsequent measurements of the same spectrum, but this is information that is generally not available experimentally. Once a precipitation event occurs, recording the same event multiple times isn't possible. Recent work on the generation of meaningful confidence intervals for biased estimators is ongoing. It may be that a practical method is found, and can then applied to the X-ray inversion problem. 

One actionable method which could be applied today, is the computation  through the forward model of many different prototype functions, and their subsequent inversion under specific assumptions on the noise and bias of the instrument in use. Given a rough form for the retrieved spectrum, using the techniques in Chapter~4, the behaviour of changes to counting statistics on the input data could be roughly quantified through monte-carlo simulations. This will depend on specific knowledge of the detector being used for a given experiment. There are no general results at present. 

The simplification obtained by ignoring the angular spectrum of the precipitating electrons also results in a loss of information that can be obtained from the data. Future detectors which have angular resolution could, in principle, be used to obtain data on the location, size, and  shape of patches of precipitating electrons. This anaylsis would require moving from a 1 dimensional representation of the inverse problem to a 2 dimensional model. Based on the computation required to generate the forward model in Chapter~3, which was done for one assumed angular distribution, the required computational resources will be large, and possibly impractical without a significant reparameterization of the model. Based on the current analysis, three dimensional histograms would need to be generated for every possible input. Hundreds of hours of computer time on significantly parallel machines was required to form the model used in this thesis, so such an approach would likely not be sucessful. What may work is the refactoring of the forward model into a set of different basis functions, such as spherical harmonics, or perhaps others, which are orthogonal, or sufficiently orthogonal to not make the inverse problem impossible.The design of detectors which can resolve angular distributions in incoming X-rays from balloons will need to take into account the ill-conditioning of the one dimensional problem. Their output will need to be simulated, and tests on synthetic data carried out, to see  how much information can be obtained from them. 

\subsection{Experimental Data}

Despite successful campaigns of zero-pressure balloons flown over months, and multiple flights of opportunity taken when satellite conjunctions are available and space weather is favorable to precipitation events, there is still a great need for more data which can be compared between balloons and spacecraft. Tests based on synthetic data alone are not sufficient to fully validate the method. For this to happen, we need pitch-angle resolved measurements of precipitating electrons in space, which are magnetically conjugate to the balloon measurements. If an expected precipitating spectrum could be detemined, free from strong assumptions on the scattering processes responsible, then a more direct comparison with the balloon data would be possible. The techniques developed in this thesis also permit the analysis of X-ray data for comparatively low intensity precipitation events when the counting statistics available in the recorded data are not very pure. Given the large dataset of the BARREL balloon flights, there are certainly events available which can be analysed, that have not yet. 

The next generation of instrumented balloons may greatly increase the depth of the available data. Work done at the University of Calgary to develop rapidly deployable, low cost, long duration balloons has shown promising initial results. When combined with lightweight solid-state detectors, and flights which permit recovery operations, it is hoped that flights of opportunity can be accomplished as active space weather conditions occur. The reduced cost and risk of this type of flight may make it an attractive platform on which to run X-ray measurement experiments. 




