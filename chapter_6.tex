\chapter{Conclusions}

\section{Analysis Methods Developed}

The primary question addressed by this thesis is how much information can reasonably be expected to be obtained from balloon measurements of X-ray spectra. The key results for the analysis methods are as follows:

\begin{itemize}
\item When accompanied by an accurate forward model of the expected instrument response given a precipitating electron spectrum, the electron spectrum can be recovered provided that the measurement noise is low enough. 
\item The required statistical purity in the measured X-ray spectrum depends on the shape of the particular spectrum being recovered, and the amount of detail sought in the solution.
\item Preconditioning techniques such as diagonal scaling improve the condition of the inverse problem with no additional assumptions or bias.
\item Biased estimators, such as truncated singular value decomposition, or Tikhonov regularization, can be applied to the to the inverse problem to make it tractable in realistic simulations and actual experiments. 
\item The application of cross-validation methods provides a way to balance the required stability of the solution against the inherent ill-conditioning of the problem, and is capable of selecting regularization parameters which represent the available information in the data without requiring heuristic arguments or detailed assumptions on the form of the output. 
\end{itemize}

These conclusions, when taken together, form a picture of the X-ray inversion problem that is quite different than what is being currently used in experiments. As discussed in Chapter 4, the ill-conditioned inverse problem needs to be addressed to obtain meaningful results. The conventional approach of assuming a particular functional form for the model electron spectrum solves the ill-conditioning by reducing the parameter space of the model. The analysis subsequently uses the well-known $\chi^2$ tests to select an optimal fit and produce an error estimate for that fit. This approach, favoured for its relative simplicity and ability to produce an error estimate, necessarily gives a misleading solution. The reason is that the uncertainty presented by the ill-conditioning of the problem, which results in the vast majority of the uncertainty in the solution, is effectively ``swept under the rug'' and contained in the assumption on the model function chosen for the solution. The remaining error analysis is trivially based on counting statistics and cannot be used to identify between different model spectra, except when significant a-priori information about the precipitating spectrum is known. 

This perspective assumes that very little useful information can be obtained from X-ray measurements. This thesis offers an alternative picture: instead of reducing the information extracted from the data to fit the analysis methods, we adapt the analysis based on what can be determined from the data in a given scenario. This picture is much more optimistic, but critically, it isn't unrealistic. The linearity of the forward problem, combined with the widespread availability of sophisticated particle transport software, makes constructing an accurate representation of the balloon experiments possible. Then, different frameworks for solving the inverse problem can be tried and compared using simulated data. We have found that some relatively simple linear algebra can be used to relieve most of the ill-conditioning of the problem, without loss of generality, but that the transformed problem still requires the use of a biased estimator to give useful, general, results in realistic situations. 

Tikhonov regularization, which is a specific form of the general techniques which modify the singular value spectra of the response matrix of the forward problem, provides a way to continuously adjust the effective dimensionality of the solution, and therefore, the amount of information solved for. Combining this parameterization with cross-validation allows for the optimized selection  of the amount of information contained in the solution, so that it neither underfits, no overfits, the available data. In particular, second-order Tikhonov regularization effectively blurs the detail in the represented solution to match the data, and requires no general assumptions on the shape of the model spectrum. Tikhonov regularization can be done using constraints which further reduce the parameter space of the problem at no additional cost. Particularly, we have found that a simple positivity constraint reduces the dispersion in model spectra. This ensemble of methods is modular - in the sense that additional constraints may be added, without additional loss of generality, if any a-priori information about the precipitating spectrum is known, for example, if magnetically local spacecraft measurements are available.

The primary cost of the use of biased estimators is that they force the mismatch between the information in the input and output of the ill-conditioned problem out in the open - we now have to handle it, and its consequences. This can be taken as a more honest view of the inverse problem in general. While the techniques in Chapter~4 provide strong results when applied to synthetic data, what they cannot do, is provide standard error bars on the shape of the output spectrum. This is because poisson statistics and their simple interpretation no longer apply in the same sense under biased estimators. Statisticians have said that the determination of meaningful error estimates for this kind of problem is one of the frontiers of their research. This places it well outside the scope of this thesis to address, and at the time of writing, only preliminary results exist, and none in the less abstract form needed for practical application to this particular problem. 

The key point is this: it is better to have the fundamental lack of information that causes the ill-conditioning of the inverse problem accounted for in some way, than to conceal it behind an assumption which cannot be justified in most experiments. By honestly attempting to, at least heuristically, account for the amount of information available in a given dataset and in a particular situation, we can learn more than by the misapplication of simple, but tractable, analysis methods.

A secondary conclusion comes from the necessity of a forward model of the precipitation process. The inverse problem, owing to its ill-conditioning, is highly sensitive to both noise, and bias, in the input data. It follows that the accuracy and precision of the forward model used to represent the problem must be high enough not to significantly affect tests on simulated data. The exact instrument response plays a key role in the forward model, and is something that cannot be adequately determined through simulation alone. Lab measurements against known X-ray spectra are required for every different experiment. These are not always easy to accomplish, owing to the somewhat random, and discrete, X-ray peaks produced by commonly available radioactive sources. Further, the instrument response needs to be well-approximated as linear with regards to energy, in order for it to be applied to the linear framework developed to address the inverse problem. The critical simplification made in Chapter~3 was that the instrument response in counts to a monochromatic beam of X-ray photons could be represented using a Green's function approach. Additionally, a large simplification of the forward problem was obtained by essentially ignoring the angular distribution of the precipitating electrons. In this sense it made the problem separable, and reduced the inverse problem to one dimension in energy only.

The environment surrounding the particular detector will need to be simulated in the forward model if it changes significantly between lab testing and installation in a balloon. Balloon experiments are hosted in insulated containers, which are usually surrounded by other flight components, some of which can interact with natural radiation in significant ways. None of this is insurmountable, but needs to be made explicit in light of the primary conclusions. All of the work in Chapter~4 and the subsequent analysis of experimental data applies because the forward model of the experiment was available and verifiable against lab data. Future experiments, even ones flown with changes only to the support systems and flight hardware, rather than instrument itself, will need to re-evaluate the conclusions of Chapter 4, based on the altered forward model of the problem. This could be seen as a lack of generality. It is instead an acknowledgement that the inverse problem is fragile to small changes in the input data and response matrix. This is not as significant of a problem when artificially suppressed by strong assumptions on the output. 

